{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97434343c71440c6a8a446cd90499a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6153e070293343498189a5cffb28f1a4",
              "IPY_MODEL_acd35c949a4b41cf8138426e98028aad",
              "IPY_MODEL_58cd62f5a35c48518a5912e7932821af"
            ],
            "layout": "IPY_MODEL_67b82229ab6e41c38d2bd337b99f045b"
          }
        },
        "6153e070293343498189a5cffb28f1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68771e00e8df471897e2ef4ba038c26d",
            "placeholder": "​",
            "style": "IPY_MODEL_8fa9ad119a8547e687c600313da774a7",
            "value": "gemma-2b.Q8_0.gguf: 100%"
          }
        },
        "acd35c949a4b41cf8138426e98028aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03944c0c3a34ba38c9a3e11e78cc091",
            "max": 2669351840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f68bd57491c4893965e6f60e32a222b",
            "value": 2669351840
          }
        },
        "58cd62f5a35c48518a5912e7932821af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257ff1f9788f4b6c9b6d11ae99b43e12",
            "placeholder": "​",
            "style": "IPY_MODEL_a16e4d29f7444c1f8906405b40782140",
            "value": " 2.67G/2.67G [00:43&lt;00:00, 51.8MB/s]"
          }
        },
        "67b82229ab6e41c38d2bd337b99f045b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68771e00e8df471897e2ef4ba038c26d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa9ad119a8547e687c600313da774a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b03944c0c3a34ba38c9a3e11e78cc091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f68bd57491c4893965e6f60e32a222b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "257ff1f9788f4b6c9b6d11ae99b43e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16e4d29f7444c1f8906405b40782140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quantized Models from the Hugging Face Community\n",
        "The other variations that interest us are based on the GGUFlibrary.\n",
        "\n",
        "We can see the different variations that GEMMA-GGML [has here](https://huggingface.co/models?sort=trending&search=gemma+gguf)."
      ],
      "metadata": {
        "id": "bODa1bS-dK-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebw363qBTqSM",
        "outputId": "b998d7a3-5b8b-4e1c-a5bf-5f0f8e2dccf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.46.tar.gz (36.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.46-cp310-cp310-manylinux_2_35_x86_64.whl size=22741834 sha256=138ce449964e303e9e63381dcf7d79cbc632fa13893876790afdd6aff6684702\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/63/cb/c1ce62664712ab6fd32f32b9e8015bc85e6b335477471be3e4\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.46\n"
          ]
        }
      ],
      "source": [
        "# With NVidia CUDA acceleration\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "o_dAcm-aVf8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"brittlewis12/gemma-2b-GGUF\"\n",
        "model_basename = \"gemma-2b.Q8_0.gguf\" # the model is in bin format"
      ],
      "metadata": {
        "id": "Tc9N7XnyVNTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "97434343c71440c6a8a446cd90499a01",
            "6153e070293343498189a5cffb28f1a4",
            "acd35c949a4b41cf8138426e98028aad",
            "58cd62f5a35c48518a5912e7932821af",
            "67b82229ab6e41c38d2bd337b99f045b",
            "68771e00e8df471897e2ef4ba038c26d",
            "8fa9ad119a8547e687c600313da774a7",
            "b03944c0c3a34ba38c9a3e11e78cc091",
            "8f68bd57491c4893965e6f60e32a222b",
            "257ff1f9788f4b6c9b6d11ae99b43e12",
            "a16e4d29f7444c1f8906405b40782140"
          ]
        },
        "id": "hR6pKCBHVhy3",
        "outputId": "64842e09-a27e-4e88-f2af-e6c2d3e4afa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gemma-2b.Q8_0.gguf:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97434343c71440c6a8a446cd90499a01"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
        "llm = Llama(\n",
        "  model_path=model_path,  # Download the model file first\n",
        "  n_ctx=32768,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
        "  n_threads=8,            # The number of CPU threads to use, tailor to your system and the resulting performance\n",
        "  n_gpu_layers=35         # The number of layers to offload to GPU, if you have GPU acceleration available\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKnv7-_xURey",
        "outputId": "06ebd682-29e9-4750-bcb8-c0c3a946ba73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 21 key-value pairs and 164 tensors from /root/.cache/huggingface/hub/models--brittlewis12--gemma-2b-GGUF/snapshots/e353e5f9dcff7ae4b11ba3c065f1f6ab4c480423/gemma-2b.Q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma\n",
            "llama_model_loader: - kv   1:                               general.name str              = gemma-2b\n",
            "llama_model_loader: - kv   2:                       gemma.context_length u32              = 8192\n",
            "llama_model_loader: - kv   3:                          gemma.block_count u32              = 18\n",
            "llama_model_loader: - kv   4:                     gemma.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   5:                  gemma.feed_forward_length u32              = 16384\n",
            "llama_model_loader: - kv   6:                 gemma.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv   7:              gemma.attention.head_count_kv u32              = 1\n",
            "llama_model_loader: - kv   8:                 gemma.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv   9:               gemma.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  10:     gemma.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  13:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  14:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  15:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,256128]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,256128]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,256128]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  20:                          general.file_type u32              = 7\n",
            "llama_model_loader: - type  f32:   37 tensors\n",
            "llama_model_loader: - type q8_0:  127 tensors\n",
            "llm_load_vocab: mismatch in special tokens definition ( 544/256128 vs 388/256128 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = gemma\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 256128\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 2048\n",
            "llm_load_print_meta: n_head           = 8\n",
            "llm_load_print_meta: n_head_kv        = 1\n",
            "llm_load_print_meta: n_layer          = 18\n",
            "llm_load_print_meta: n_rot            = 256\n",
            "llm_load_print_meta: n_embd_head_k    = 256\n",
            "llm_load_print_meta: n_embd_head_v    = 256\n",
            "llm_load_print_meta: n_gqa            = 8\n",
            "llm_load_print_meta: n_embd_k_gqa     = 256\n",
            "llm_load_print_meta: n_embd_v_gqa     = 256\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 16384\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 2B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 2.51 B\n",
            "llm_load_print_meta: model size       = 2.48 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = gemma-2b\n",
            "llm_load_print_meta: BOS token        = 2 '<bos>'\n",
            "llm_load_print_meta: EOS token        = 1 '<eos>'\n",
            "llm_load_print_meta: UNK token        = 3 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<pad>'\n",
            "llm_load_print_meta: LF token         = 227 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.13 MiB\n",
            "llm_load_tensors: offloading 18 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 19/19 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   531.52 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  2539.93 MiB\n",
            "................................................\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            "llama_new_context_with_model: n_ctx      = 32768\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   576.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  576.00 MiB, K (f16):  288.00 MiB, V (f16):  288.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host input buffer size   =    69.26 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   592.13 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     4.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 3\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'general.file_type': '7', 'tokenizer.ggml.unknown_token_id': '3', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '1', 'general.architecture': 'gemma', 'gemma.feed_forward_length': '16384', 'gemma.attention.head_count': '8', 'general.name': 'gemma-2b', 'gemma.context_length': '8192', 'gemma.block_count': '18', 'gemma.embedding_length': '2048', 'gemma.attention.head_count_kv': '1', 'gemma.attention.key_length': '256', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'gemma.attention.value_length': '256', 'gemma.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text completion"
      ],
      "metadata": {
        "id": "tzjbuDMSa1Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =  \"Simply put, the theory of relativity states that \"\n",
        "prompt_template=f'{prompt}'\n",
        "\n",
        "response=llm(prompt=prompt_template, max_tokens=512, temperature=0.7, top_p=0.95,\n",
        "                  repeat_penalty=1.1, top_k=150,\n",
        "                  echo=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV43akCWWvGb",
        "outputId": "b6add256-640b-485f-80ed-c8e7b193786b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =      91.04 ms\n",
            "llama_print_timings:      sample time =    3046.05 ms /   512 runs   (    5.95 ms per token,   168.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =      86.36 ms /    10 tokens (    8.64 ms per token,   115.79 tokens per second)\n",
            "llama_print_timings:        eval time =    9236.03 ms /   511 runs   (   18.07 ms per token,    55.33 tokens per second)\n",
            "llama_print_timings:       total time =   24410.64 ms /   521 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1C2w3qY6u4",
        "outputId": "7e85732b-ac7a-4bd6-ea3b-23eba8f9f30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simply put, the theory of relativity states that <strong>the faster an object moves relative to another object, the slower its motion appears to other objects.</strong>\n",
            "\n",
            "The difference between light-time and time dilation is that light-time only affects the direction of travel; time dilation also changes the rate at which clocks tick (time).  This means that if two observers measure different rates for the same physical event, one must be moving with respect to the other.\n",
            "\n",
            "The effects of time dilation are most noticeable for observers traveling at relativistic speeds, or close to it.  If two observers are moving in opposite directions with respect to each other (i.e. one is approaching from behind), they will experience time dilations with respect to each other’s clocks but not with respect to their own.  As a result, it would appear that one observer’s clock ticks more slowly than the other’s (as measured by his/her own clock).\n",
            "\n",
            "Time dilation can be observed in many ways, including:\n",
            "\n",
            "* The length of an object’s path through space (e.g. a spacecraft traveling at a high speed will appear shorter from the perspective of an observer on Earth).\n",
            "* The speed of a moving object’s movement through space (e.g. a spacecraft traveling at a high speed will appear to be moving more slowly than an observer on Earth would expect).\n",
            "* The duration of a physical event (e.g. a spacecraft traveling at a high speed will appear to have passed more quickly than an observer on Earth would expect).\n",
            "\n",
            "Time dilation can be explained by the fact that as an object moves closer to the speed of light, it approaches a point where its mass increases significantly (known as the speed of light).  At this point, any physical event occurring within an object’s mass will take longer for that object’s observer to experience than it would if the object were stationary.\n",
            "\n",
            "<h2>Time Dilation Explained</h2>\n",
            "\n",
            "Time dilation is a consequence of special relativity, which states that time passes more slowly for objects moving at relativistic speeds than for objects moving at non-relativistic speeds.  The more mass an object has, the slower it will appear to pass time for any observer who measures it.  This means that if two observers are moving in opposite directions with respect to each other (i.e. one is approaching from behind), they will experience time dilations with respect to each other’s clocks but not with respect to their own.\n",
            "\n",
            "As a result, it would appear that one observer’s clock ticks more slowly than the other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat"
      ],
      "metadata": {
        "id": "BSuTT1PNe_Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a project idea that helps the kids how to read\"\n",
        "prompt_template=f'''SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "'''\n",
        "\n",
        "response=llm(prompt=prompt_template, max_tokens=256, temperature=0.7, top_p=0.95,\n",
        "                  repeat_penalty=1.1, top_k=150,\n",
        "                  echo=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWFUAzFTZON4",
        "outputId": "fa3c17b7-1928-4194-daee-8d5192fe7c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =      91.04 ms\n",
            "llama_print_timings:      sample time =    1320.95 ms /   223 runs   (    5.92 ms per token,   168.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =      73.34 ms /    41 tokens (    1.79 ms per token,   559.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4010.12 ms /   222 runs   (   18.06 ms per token,    55.36 tokens per second)\n",
            "llama_print_timings:       total time =   10605.13 ms /   263 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQJ-28WFZQ65",
        "outputId": "815f0c7d-9c2f-4f19-db46-f3fc001d09d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
            "\n",
            "USER: Write a poem that helps me to remember 10 elements of periodic table\n",
            "\n",
            "ASSISTANT:\n",
            "1. The Periodic Table shows the relationship between different elements. It is arranged in order of increasing atomic number.\n",
            "2. The vertical columns are called families or periods. Each family consists of all elements having similar properties.\n",
            "3. The horizontal rows are called groups or periods. Each group consists of all elements having similar properties.\n",
            "4. The element with smallest atomic number is Hydrogen (H) while the element with largest atomic number is Uranium (U).\n",
            "5. The element with smallest atomic mass is Lithium (Li) while the element with largest atomic mass is Uranium (U).\n",
            "6. The element with smallest atomic weight is Helium (He) while the element with largest atomic weight is Uranium (U).\n",
            "7. The element with smallest atomic number is Hydrogen (H) while the element with largest atomic number is Uranium (U).\n",
            "8. The element with smallest atomic mass is Lithium (Li) while the element with largest atomic mass is Uranium (U).\n",
            "9. The element with smallest atomic weight is Helium (He) while the element with largest atomic weight is Uranium (U).\n"
          ]
        }
      ]
    }
  ]
}